Sender: LSF System <lsfadmin@host323.jc.rl.ac.uk>
Subject: Job 4003853: <PingPong> in cluster <lotus> Done

Job <PingPong> was submitted from host <lotus.jc.rl.ac.uk> by user <ciddon> in cluster <lotus>.
Job was executed on host(s) <1*host323.jc.rl.ac.uk>, in queue <par-multi>, as user <ciddon> in cluster <lotus>.
                            <1*host341.jc.rl.ac.uk>
</home/users/ciddon> was used as the home directory.
</home/users/ciddon/JASMIN_IMB> was used as the working directory.
Started at Thu Mar 23 10:33:01 2017
Results reported on Thu Mar 23 10:34:54 2017

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -x
#BSUB -q par-multi
#BSUB -n 2
#BSUB -R "span[ptile=1]"
#BSUB -J PingPong
#BSUB -o /home/users/ciddon/JASMIN_IMB/outputs/%J.out
#BSUB -e /home/users/ciddon/JASMIN_IMB/outputs/%J.err
#BSUB -W 0:30
#BSUB -m "broadwell256G"
mpirun.lotus -prot /home/users/ciddon/JASMIN_IMB/imb/imb/src/IMB-MPI1 -iter 1000 -time 70 -msglog 0:24 -iter_policy off PingPong

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   111.10 sec.
    Max Memory :                                 52.90 MB
    Average Memory :                             40.40 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   8784 MB
    Max Processes :                              10
    Max Threads :                                12

The output (if any) follows:

Parsing application description...
Identifying hosts...
Spawning processes...
Process layout for world 0 is as follows:
mpirun:  proc 150652
  daemon proc 150655 on host 192.168.118.23
    rank 0:  proc 150663
  daemon proc 11255 on host 192.168.118.41
    rank 1:  proc 11277
Host 0 -- ip 192.168.118.23 -- ranks 0
Host 1 -- ip 192.168.118.41 -- ranks 1

 host | 0    1
======|===========
    0 : SHM  TCP
    1 : TCP  SHM

 Prot -  All Intra-node communication is: SHM
 Prot -  All Inter-node communication is: TCP

#------------------------------------------------------------
#    Intel (R) MPI Benchmarks 2017, MPI-1 part    
#------------------------------------------------------------
# Date                  : Thu Mar 23 10:33:02 2017
# Machine               : x86_64
# System                : Linux
# Release               : 2.6.32-642.11.1.el6.x86_64
# Version               : #1 SMP Wed Oct 26 10:25:23 EDT 2016
# MPI Version           : 2.2
# MPI Thread Environment: 


# Calling sequence was: 

# /home/users/ciddon/JASMIN_IMB/imb/imb/src/IMB-MPI1 -iter 1000 -time 70 -msglog 0:24
#                                                    -iter_policy off PingPong

# Minimum message length in bytes:   0
# Maximum message length in bytes:   16777216
#
# MPI_Datatype                   :   MPI_BYTE 
# MPI_Datatype for reductions    :   MPI_FLOAT
# MPI_Op                         :   MPI_SUM  
#
#

# List of Benchmarks to run:

# PingPong

#---------------------------------------------------
# Benchmarking PingPong 
# #processes = 2 
#---------------------------------------------------
       #bytes #repetitions      t[usec]   Mbytes/sec
            0         1000         6.01         0.00
            1         1000         6.10         0.16
            2         1000         6.07         0.31
            4         1000         6.11         0.62
            8         1000         6.31         1.21
           16         1000         6.28         2.43
           32         1000         6.25         4.88
           64         1000         6.28         9.72
          128         1000         6.46        18.91
          256         1000         6.67        36.61
          512         1000         7.06        69.13
         1024         1000         7.94       123.02
         2048         1000        10.44       187.12
         4096         1000        12.35       316.23
         8192         1000        18.52       421.93
        16384         1000        26.76       583.84
        32768         1000        55.17       566.39
        65536         1000        88.03       710.01
       131072         1000       142.53       876.98
       262144         1000       249.43      1002.27
       524288         1000       458.65      1090.16
      1048576         1000       882.86      1132.68
      2097152         1000      1730.88      1155.48
      4194304         1000      3426.11      1167.50
      8388608         1000      6820.91      1172.86
     16777216         1000     13607.51      1175.82


# All processes entering MPI_Finalize



PS:

Read file </home/users/ciddon/JASMIN_IMB/outputs/4003853.err> for stderr output of this job.

