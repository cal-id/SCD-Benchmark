Sender: LSF System <lsfadmin@host208.jc.rl.ac.uk>
Subject: Job 4003811: <PingPong> in cluster <lotus> Done

Job <PingPong> was submitted from host <lotus.jc.rl.ac.uk> by user <ciddon> in cluster <lotus>.
Job was executed on host(s) <1*host208.jc.rl.ac.uk>, in queue <par-multi>, as user <ciddon> in cluster <lotus>.
                            <1*host205.jc.rl.ac.uk>
</home/users/ciddon> was used as the home directory.
</home/users/ciddon/JASMIN_IMB> was used as the working directory.
Started at Fri Mar 24 11:03:22 2017
Results reported on Fri Mar 24 11:05:16 2017

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -x
#BSUB -q par-multi
#BSUB -n 2
#BSUB -R "span[ptile=1]"
#BSUB -J PingPong
#BSUB -o /home/users/ciddon/JASMIN_IMB/outputs/%J.out
#BSUB -e /home/users/ciddon/JASMIN_IMB/outputs/%J.err
#BSUB -W 0:30
#BSUB -m "ivybridge512G"
mpirun.lotus -prot /home/users/ciddon/JASMIN_IMB/imb/imb/src/IMB-MPI1 -iter 1000 -time 70 -msglog 0:24 -iter_policy off PingPong

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   112.41 sec.
    Max Memory :                                 58.16 MB
    Average Memory :                             45.64 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   8791 MB
    Max Processes :                              10
    Max Threads :                                12

The output (if any) follows:

Parsing application description...
Identifying hosts...
Spawning processes...
Process layout for world 0 is as follows:
mpirun:  proc 2820
  daemon proc 2823 on host 192.168.113.208
    rank 0:  proc 2831
  daemon proc 11981 on host 192.168.113.205
    rank 1:  proc 12018
Host 0 -- ip 192.168.113.208 -- ranks 0
Host 1 -- ip 192.168.113.205 -- ranks 1

 host | 0    1
======|===========
    0 : SHM  TCP
    1 : TCP  SHM

 Prot -  All Intra-node communication is: SHM
 Prot -  All Inter-node communication is: TCP

#------------------------------------------------------------
#    Intel (R) MPI Benchmarks 2017, MPI-1 part    
#------------------------------------------------------------
# Date                  : Fri Mar 24 11:03:23 2017
# Machine               : x86_64
# System                : Linux
# Release               : 2.6.32-696.el6.x86_64
# Version               : #1 SMP Tue Feb 21 00:53:17 EST 2017
# MPI Version           : 2.2
# MPI Thread Environment: 


# Calling sequence was: 

# /home/users/ciddon/JASMIN_IMB/imb/imb/src/IMB-MPI1 -iter 1000 -time 70 -msglog 0:24
#                                                    -iter_policy off PingPong

# Minimum message length in bytes:   0
# Maximum message length in bytes:   16777216
#
# MPI_Datatype                   :   MPI_BYTE 
# MPI_Datatype for reductions    :   MPI_FLOAT
# MPI_Op                         :   MPI_SUM  
#
#

# List of Benchmarks to run:

# PingPong

#---------------------------------------------------
# Benchmarking PingPong 
# #processes = 2 
#---------------------------------------------------
       #bytes #repetitions      t[usec]   Mbytes/sec
            0         1000         9.10         0.00
            1         1000         9.54         0.10
            2         1000         9.54         0.20
            4         1000         9.51         0.40
            8         1000         9.94         0.77
           16         1000        10.24         1.49
           32         1000        10.25         2.98
           64         1000        10.30         5.93
          128         1000        10.60        11.52
          256         1000        10.80        22.60
          512         1000        11.25        43.42
         1024         1000        12.20        80.03
         2048         1000        14.16       137.92
         4096         1000        17.40       224.52
         8192         1000        24.36       320.65
        16384         1000        33.73       463.20
        32768         1000        66.73       468.28
        65536         1000        99.96       625.24
       131072         1000       154.42       809.46
       262144         1000       261.48       956.08
       524288         1000       472.21      1058.85
      1048576         1000       897.24      1114.53
      2097152         1000      1749.63      1143.10
      4194304         1000      3440.03      1162.78
      8388608         1000      6843.09      1169.06
     16777216         1000     13637.26      1173.26


# All processes entering MPI_Finalize



PS:

Read file </home/users/ciddon/JASMIN_IMB/outputs/4003811.err> for stderr output of this job.

